Dual process theory makes a dichotomy between fast, automatic, unconcious heuristics and slow, deliberate, rational thought. Togethor, these processes minimize cognitive energy expendature over a broader domain of activities than could be acheived individually. However in the greater scope of natural intelligence, these are only two frequency bands along the spectrum of optimization. Similar to \cite{Mondol2020}, I consider this great learning spectrum in three parts: population optimization, direct learning, and indirect learning. (See Figure \cite{fig:2})

%%%%%%%%%%%%%whole page figure%%%%%%%%%%%%%%%%%%%%%%%%%%    
\begin{figure}
 \def\naturePopulationOptimization{\begin{itemize}
    \item Slow
    \item No individual feedback; Population is learning
    \item Organism designs selected; accompanies environment change
    \end{itemize}}
 \def\aiPopulationOptimization{\begin{itemize}
    \item Relatively slow
    \item AI not aware of this phase of optimization
    \item Humans design agent and training pipeline which often includes selecting datasets or environments
    \end{itemize}}
 \def\natureDirectLearning{\begin{itemize}
    \item Physiological adaptation, classical conditioning, culture transmission, imitation
    \item Depending on the type of learning, organism learns after many or only a few action-stimulus experiences with real data
    \item Genetic priors shape learned behaviors
    \end{itemize}}
 \def\aiDirectLearning{\begin{itemize}
    \item Supervised learning, reinforcement learning
    \item Usually many dataset examples or environment interactions required to learn
    \item ML setup especially reward function strongly shape behavior
    \end{itemize}}
 \def\natureIndirectLearning{\begin{itemize}
    \item Imagination, Planning, Reasoning, Empathy
    \item Fast interpersonal information transmission and extremely fast internal processing
    \item Generalizes to unseen compositions, experiences, or actions
    \end{itemize}}
 \def\aiIndirectLearning{\begin{itemize}
    \item Unsupervised learning, in-context learning, zero/one/few-shot learning
    \item Would greatly reduce dataset demands
    \item This would realize the goal of transfer learning
    \end{itemize}}

 \centering
 \input{images/learning_table.pdf_tex}
 %\resizebox{\textwidth}{!}{\input{images/learning_table.pdf_tex}}
 \label{fig:2}
 \caption{Learning happens over a spectrum of frequency loosely categorized as population optimization, direct learning, and indirect learning. }
\end{figure}

\paragraph{Population optimization} begins with a prior. From an information–energetic perspective this is only appropriate: energy cannot be created or destroyed. However it can be collected from the environment. Much as an organism requires physical energy through its life and grows accordingly, successive layers of population-level optimization, direct learning, and indirect learning collect information from the organism’s niche to grow in intelligence. Information gained in population-level optimization may also be passed on to future generations. In biological life, DNA comprises much of the information bottleneck. 

It is important to emphasize here: the organism does not actually learn at this phase in optimization. It never even feedback. However, the organisms life provides feedback to the DNA which, in turn, lives by means of all its organisms — much as an organism lives by all its cells. While population optimization is slow from a human perspective, its prior knowledge make DNA a few-shot learner. On the order of dozen to hundreds of generations, its genome pool optimizes lactose tolerance, skin pigmentation, eye color, height, and lung capacity –to name a few genotypes. 

Few artificially intelligence systems today feature population optimization as complex as biological life, but this does not preclude any adaptation. In most contexts, humans perform artificial selection and often also conceptual mutation when implementing a new AI system. This means all design information typically flows through the engineers mind before being expressed in a software system. Training data sets are usually selected by machine learning engineers. The advent of reinforcement learning has enabled some AI systems to select their own data, however machine learning systems generally do not optimize for this. Like nature, this is a slow process, but in contrast, AI in general has little prior knowledge to accelerate training. Any contributions researchers have to share with AI are learned at the population-optimization phase. 

\paragraph{Direct learning} emphasizes real encounters, actual sensory experiences, and physical involvement. 

The reinforcement learning perspective is ``give me the agent's reward function, and I'll give you it's policy''. In the case of supervised learning, the loss function and dataset togethor comprise a reward system that biases the networks behavior in an adaptive direction. The ``crystal intelligence'' ML pipeline passes its knowledge onto the ``fluid intelligence'' neural network.

\paragraph{Indirect learning} uses highly structured information tools such as natural language to cognitively process never before seen data and adapt behavior appropriately. This division of the learning spectrum covers extremely high learning frequencies loosely ranging from interpersonal conversation to whole brain gamma wave synchrony. Rather than learning from other organisms' data (population-optimization) or real data (direct learning), indirect learning synthesizes its own data to learn from. By social, cognitive, and formal mechanisms, humans are capable of reasoning, planning, imagining, expressing, and evaluating information that simply could not be directly observed by a human. This form of learning currently gives humans an unrivaled competitive advantage over animals and machines in numerous human-level skill domains. As Isaac Newton well stated ``If I have seen further it is by standing on the shoulders of Giants'' \cite{Chen2003}.

In contrast, artificial intelligence systems currently struggle with indirect learning. They usually must experience the same or similar data many times during training to just produce a fuzzy representation of it (CITE AUTOENCODERS). Simply percieving or synthesizing data realistically is an unmet prerequisite to indirect learning. This is closely associated with the binding problem: connecting useful parts to wholes -- and doing so in a way that can be compositionally generalized \cite{Klaus2020}. This process may further be subdivided as segmentation, representation, and composition. In segmentation, discrete partitions in time and space are made from sensory data. Representation transforms these partitions into useful pieces of information. Finally composition describes the relationship between individual segments of data. The ideal result of these processes is highly integrated information both useful for the immediate task at hand and also structured in a way such that individual parts may be swapped out with new information and downstream neural mechanisms generalize appropriately.

Some progress has been made towards indirect learning in artificial intelligence. This has included more accurate models for reinforcement learning including \cite{hafner2020dreamerv2,Guan2019,ha2018worldmodels}, language acquisition tests\cite{Mondol2020}, and language-grounding environments like Serdo \cite{Pothula2020}, \verb|rl-lang-ground| \cite{8658389}, and BabyAI \cite{hui2020babyai,babyai_iclr19}. 

After considering the pipeline between these three forms of learning, it is natural to wonder if there is another form of optimization occuring at higher frequencies. Even implementing the preceeding learning spectrum into an AI system would be a novel accomplishment. This would give AI 1) open-ended autonomous growth, 2) machine learning   and 3) transfer learning capabilities. 
