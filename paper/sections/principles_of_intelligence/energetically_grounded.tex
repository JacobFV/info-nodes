Intelligence begins with information (CITE) which, in turn, depends on energy. Under any probability distribution $p$, information theory even equates information with energy by $E(x) = - \log{p(x)} $ (CITE). With this negative log-likelihood relationship, it is easy to see that unexpected events are therefore energetic ones. For instance, signaling with prior-optimized codebook, the cross entropy of a signal directly relates both electrical energy consumed and information transmitted. (CITE) Likewise EEG's are used to approximate the information processing involvement of a brain region by measuring its glucose energy metabolism. (CITE)

This is not to make intelligence the same as energy -- anymore than information is equal to data: all signals carry data, but only some are informative. Quantifying information is, however, a first step to appreciating its application. Using ``skill-acquisition efficiency [\dots] with respect to priors, experience, and generalization difficulty'' as a measure of intelligence \citep[27]{Chollet2019}, comparisons can be made to energy-efficency which measures energetic output with respect to input. There exist reversible processes that lose no energy in their evolution. Analogously, one may identify information superconductos such as bijectors, quantum logic gates, and reversible particle interactions which are perfectly efficent in data consumption. This is the objective of few-shot, one-shot, in-context, transfer, and meta-learning. However the typical reality is that machine learning is data-hungry. As training set size increases, the ratio of informative to old examples one decreases thus resulting in logarithmic training improvement similar to how thermodynamic conduction from a constant head source results in diminishing energy transfer. However, there is a workaround to this challange on the meso-scale. In 1867, James Maxwell suggested the famous thought experiment later known as \textit{Maxwell's demon} where two gas vessels are connected and at equal pressure with an effectively zero-mass openable hole between them. When cooler gas particles in the first container happen by entropic motion to head toward the second, the hole is opened to allow pasage; reciporically, only hotter gas particles are allows to move from the second container to the first. Maxwell hypothesized:
\begin{quote}
 Then the number of molecules in A and B are the same as at first, but the energy in A is increased and that in B diminished, that is, the hot system has got hotter and the cold colder and yet no work has been done, only the intelligence of a very observant and neat-fingered being has been employed. \cite[214]{knott_tait_2015}
\end{quote}
On the micro-scale, this does not work since the prior information-energy required to determine when to open or close the door is simply being exchanged for physical energy. On the meso-scale though, something similar is possible. With focus on machine learning, \we ask:
\begin{center}
 Can \we make a machine learning system that adaptively selects it own data?
\end{center}
\We are not suggesting it would be possible to actually violate the second law of thermodynamics, but there exist sufficent assymetries in information that is already stored in datasets which a meta-machine learning system may exploit to maximize data-performance efficency. This is an extension of AutoML to data selection; and curiosity and hard attention to meta-learning. Such a system would only need to sample a few dataset elements a dataset to approximate their population parameters. It could adversarially bias the training pipeline to select data that has greatest informative value to the optimization process -- equivalently, that which the system dually shows greatest loss before and fastest improvement after training on.  
